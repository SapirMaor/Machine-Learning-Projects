{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Assignment 3\n",
        "## Submitted by(id's):\n",
        "*   207496951\n",
        "*   322217456"
      ],
      "metadata": {
        "id": "BwHffKRukgyT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAxNDFdNcJ38"
      },
      "source": [
        "# Preliminary data analysis and Preprocessing\n",
        "*   Loading the data and spliting into train, test, dev\n",
        "*   Understanding the data and the need for a regression model\n",
        "*   Finding the range of the target values before and after scaling\n",
        "*   Determining the data has missing/Nan values in some features and replacing them with the mean values of the corresponding feature\n",
        "*   Plotting the histograms of each feature\n",
        "*   Scaling the data to get a mean of 0 and a variance of 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hWOJl61ZhSEc",
        "outputId": "57bba61b-8d47-4586-86c1-fbea45799172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes:\n",
            "Train shape: (12384, 9)\n",
            "Number of train samples: 12384\n",
            "Dev shape: (4128, 9)\n",
            "Number of dev samples: 4128\n",
            "Test shape:  (4128, 9)\n",
            "Number of test samples: 4128 \n",
            "\n",
            "Feature data:\n",
            "Number of features: 9\n",
            "Target range before scaling: [ 0.14999 ,  5.00001 ]\n",
            "Statistics for each feature in train before preprocessing:\n",
            "                  f0            f1            f2            f3            f4  \\\n",
            "count  12210.000000  12244.000000  12226.000000  12228.000000  12215.000000   \n",
            "mean       3.872771     28.630595      5.420978      1.096626   1426.830618   \n",
            "std        1.919183     12.566127      2.382548      0.471398   1103.528284   \n",
            "min        0.499900      1.000000      0.846154      0.500000      3.000000   \n",
            "25%        2.555600     18.000000      4.430232      1.006386    786.000000   \n",
            "50%        3.534100     29.000000      5.218429      1.049202   1170.000000   \n",
            "75%        4.745975     37.000000      6.043349      1.099202   1739.000000   \n",
            "max       15.000100     52.000000    132.533333     34.066667  28566.000000   \n",
            "\n",
            "                 f5            f6            f7        target  \n",
            "count  12242.000000  12233.000000  12236.000000  12384.000000  \n",
            "mean       3.144714     35.626833   -119.561040      2.066362  \n",
            "std       13.440452      2.133539      1.996646      1.147908  \n",
            "min        0.692308     32.550000   -124.350000      0.149990  \n",
            "25%        2.428571     33.940000   -121.790000      1.198000  \n",
            "50%        2.816384     34.250000   -118.490000      1.798000  \n",
            "75%        3.276456     37.710000   -118.020000      2.646000  \n",
            "max     1243.333333     41.950000   -114.550000      5.000010   \n",
            "\n",
            "Statistics for each feature in train after processing:\n",
            "                   0             1             2             3             4  \\\n",
            "count  12384.000000  12384.000000  12384.000000  12384.000000  12384.000000   \n",
            "mean       3.872771     28.630595      5.420978      1.096626   1426.830618   \n",
            "std        1.905652     12.494890      2.367300      0.468419   1095.972079   \n",
            "min        0.499900      1.000000      0.846154      0.500000      3.000000   \n",
            "25%        2.566700     18.000000      4.440897      1.006920    791.000000   \n",
            "50%        3.559900     28.630595      5.235404      1.050420   1181.000000   \n",
            "75%        4.723550     37.000000      6.026188      1.098183   1725.250000   \n",
            "max       15.000100     52.000000    132.533333     34.066667  28566.000000   \n",
            "\n",
            "                  5             6             7             8  \n",
            "count  12384.000000  12384.000000  12384.000000  12384.000000  \n",
            "mean       3.144714     35.626833   -119.561040      2.066362  \n",
            "std       13.363166      2.120491      1.984678      1.147908  \n",
            "min        0.692308     32.550000   -124.350000      0.149990  \n",
            "25%        2.433411     33.940000   -121.770000      1.198000  \n",
            "50%        2.824490     34.270000   -118.520000      1.798000  \n",
            "75%        3.268952     37.700000   -118.020000      2.646000  \n",
            "max     1243.333333     41.950000   -114.550000      5.000010   \n",
            "\n",
            "Feature histograms:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Data scaling:\n",
            "Statistics for each feature in train after scaling:\n",
            "                   0             1             2             3             4  \\\n",
            "count  1.238400e+04  1.238400e+04  1.238400e+04  1.238400e+04  1.238400e+04   \n",
            "mean   1.583574e-16 -5.049076e-17  2.584783e-16  1.704063e-16 -4.876949e-18   \n",
            "std    1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00   \n",
            "min   -1.770002e+00 -2.211441e+00 -1.932585e+00 -1.273753e+00 -1.299201e+00   \n",
            "25%   -6.853947e-01 -8.508297e-01 -4.140245e-01 -1.915153e-01 -5.801756e-01   \n",
            "50%   -1.641871e-01  0.000000e+00 -7.839364e-02 -9.864660e-02 -2.243128e-01   \n",
            "75%    4.464686e-01  6.698533e-01  2.556648e-01  3.323907e-03  2.722984e-01   \n",
            "max    5.839356e+00  1.870393e+00  5.369725e+01  7.038859e+01  2.476365e+01   \n",
            "\n",
            "                  5             6             7             8  \n",
            "count  1.238400e+04  1.238400e+04  1.238400e+04  1.238400e+04  \n",
            "mean  -9.180139e-18  3.630745e-15 -2.282986e-15 -3.614680e-17  \n",
            "std    1.000040e+00  1.000040e+00  1.000040e+00  1.000040e+00  \n",
            "min   -1.835273e-01 -1.451059e+00 -2.413063e+00 -1.669515e+00  \n",
            "25%   -5.323081e-02 -7.955240e-01 -1.113051e+00 -7.565039e-01  \n",
            "50%   -2.396417e-02 -6.398933e-01  5.245598e-01 -2.337929e-01  \n",
            "75%    9.297427e-03  9.777220e-01  7.765000e-01  5.049721e-01  \n",
            "max    9.281024e+01  2.982056e+00  2.524965e+00  2.555751e+00   \n",
            "\n",
            "Statistics for each feature in dev after scaling:\n",
            "                  0            1            2            3            4  \\\n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000  4128.000000   \n",
            "mean     -0.003097    -0.007234    -0.001115    -0.007600    -0.016586   \n",
            "std       0.963659     1.017920     0.960491     0.934235     1.005017   \n",
            "min      -1.770002    -2.211441    -1.707707    -1.629574    -1.290076   \n",
            "25%      -0.673063    -0.850830    -0.406874    -0.192999    -0.585879   \n",
            "50%      -0.180167    -0.050470    -0.076283    -0.103425    -0.249406   \n",
            "75%       0.472681     0.669853     0.265244     0.009211     0.248346   \n",
            "max       5.839356     1.870393    24.079565    30.349834    10.789186   \n",
            "\n",
            "                 5            6            7            8  \n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000  \n",
            "mean     -0.013692     0.003180    -0.011353     0.005094  \n",
            "std       0.115834     1.007357     1.009897     0.997244  \n",
            "min      -0.144346    -1.446343    -2.367714    -1.669515  \n",
            "25%      -0.053715    -0.795524    -1.133207    -0.742783  \n",
            "50%      -0.024611    -0.639893     0.534637    -0.222903  \n",
            "75%       0.010939     0.987154     0.791616     0.514773  \n",
            "max       4.535432     2.911315     2.555198     2.555751   \n",
            "\n",
            "Target range after scaling: [ -1.6695146480709162 ,  2.5557505566430883 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "my_dict = pickle.load(open('./ass3.pickle', 'rb'))\n",
        "train, test, dev = my_dict[\"train\"], my_dict[\"test\"], my_dict[\"dev\"]\n",
        "\n",
        "print(\"Data shapes:\")\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Number of train samples:\", train.shape[0])\n",
        "print(\"Dev shape:\", dev.shape)\n",
        "print(\"Number of dev samples:\", dev.shape[0])\n",
        "print(\"Test shape: \", test.shape)\n",
        "print(\"Number of test samples:\", test.shape[0],\"\\n\")\n",
        "\n",
        "print(\"Feature data:\")\n",
        "print(\"Number of features:\", train.shape[1])\n",
        "\n",
        "target = train.values[:, -1]\n",
        "print(\"Target range before scaling:\", \"[\", np.min(target), \", \", np.max(target), \"]\")\n",
        "\n",
        "#Train\n",
        "df_train = pd.DataFrame(train)\n",
        "print(\"Statistics for each feature in train before preprocessing:\\n\", df_train.describe(),\"\\n\")\n",
        "# We can see that we have some samples without certain features\n",
        "# We will replace these Nan values with the mean value of it's corresponding feature:\n",
        "\n",
        "feature_mean = df_train.mean(axis=0)\n",
        "feature_mean = feature_mean.to_numpy()\n",
        "\n",
        "train = train.to_numpy()\n",
        "for row in train:\n",
        "  for feature_index in range(0,8):\n",
        "    if np.isnan(row[feature_index]):\n",
        "      row[feature_index] = feature_mean[feature_index]\n",
        "\n",
        "df_train = pd.DataFrame(train)\n",
        "print(\"Statistics for each feature in train after processing:\\n\", df_train.describe(),\"\\n\")\n",
        "\n",
        "print(\"Feature histograms:\")\n",
        "# Plotting a histogram for 8 features\n",
        "num_of_features = 8\n",
        "fig, axs = plt.subplots(1, num_of_features, figsize=(15, 3))\n",
        "\n",
        "for i in range(num_of_features):\n",
        "    axs[i].hist(train[:, i], bins=25, color='skyblue', edgecolor='black')\n",
        "    axs[i].set_xlabel(f\"Feature {i+1} range\")\n",
        "    axs[i].set_ylabel(\"Number of sample points\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Data scaling:\")\n",
        "#Scaling the data:\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train)\n",
        "scaled_train = scaler.transform(train)\n",
        "scaled_dev = scaler.transform(dev)\n",
        "\n",
        "df_train = pd.DataFrame(scaled_train)\n",
        "print(\"Statistics for each feature in train after scaling:\\n\", df_train.describe(),\"\\n\")\n",
        "df_dev = pd.DataFrame(scaled_dev)\n",
        "print(\"Statistics for each feature in dev after scaling:\\n\", df_dev.describe(),\"\\n\")\n",
        "\n",
        "target = scaled_train[:, -1]\n",
        "print(\"Target range after scaling:\", \"[\", np.min(target), \", \", np.max(target), \"]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz25Op29Epx6"
      },
      "source": [
        "*   Separating target labels from the actual data (into X and y)\n",
        "*   Creating a new training set which consists of the train and dev data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kPPkrb50OQ0z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# train_array = train.values\n",
        "\n",
        "X_train = scaled_train[:, :-1]\n",
        "y_train = scaled_train[:, -1]\n",
        "\n",
        "X_dev = scaled_dev[:, :-1]\n",
        "y_dev = scaled_dev[:, -1]\n",
        "\n",
        "final_Xtrain = np.concatenate((X_train, X_dev))\n",
        "final_Ytrain = np.concatenate((y_train, y_dev))\n",
        "\n",
        "finalTestArray = test.values\n",
        "finalX_test = finalTestArray[:, :-1]\n",
        "finalY_test = finalTestArray[:, -1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note:\n",
        "\n",
        "We will be using the metric \"mean squared error\" to evaluate the models errors throughout our assignment. Therefore, we are searching for the *lowest* error we can get. Also, for some of the models, we searched for hyperparameters using different search methods such as GridSearch and RandomizedSearch."
      ],
      "metadata": {
        "id": "IVXi-g3PwFG1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spVmlI4cKbSt"
      },
      "source": [
        "# K Nearest Neighbors\n",
        "We understood from our preliminary data analysis that we need a regression model.\n",
        "\n",
        "The first model we tried was KNN. As we know it is a simple algorithm that doesn't need specific information about the data.\n",
        "\n",
        "The only hyperparameter that needs to be tuned is K- the number of neighbors that are taken into consideration.\n",
        "\n",
        "Since this algorithm is sensitive to missing values and needs feature scaling, and we handled this in the preprocessing stage, we thought it would be a good choice.\n",
        "\n",
        "We received an error of 0.327.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "64P8RPQiLSTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5nbbVu3GWj",
        "outputId": "6910363c-3dad-4a7c-b9fe-5a56b76bd01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best param: 15\n",
            "Mean Squared Error: 0.3298093070332293\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {'n_neighbors': range(1,100)}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(knn, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best param:\", grid_search.best_params_['n_neighbors'])\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_knn = grid_search.best_estimator_\n",
        "best_knn.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ *  -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "QQa4wxriLf6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Creating the regressor\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {'n_neighbors': randint(1, 100)}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(knn, params, scoring='neg_mean_squared_error', cv=10, n_iter=20)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best param:\", random_search.best_params_['n_neighbors'])\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_knn_randSearch = random_search.best_estimator_\n",
        "best_knn_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ *  -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-iOw3wPLoVh",
        "outputId": "c61a6078-3e6c-464c-aad0-22b0acec986f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best param: 16\n",
            "Mean Squared Error: 0.3273269152118609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD9c6eBmEZA5"
      },
      "source": [
        "# Linear Regression\n",
        "Another simple algorithm we tried was Linear Regression.\n",
        "\n",
        "We chose to tune the following hyperparameters:\n",
        "\n",
        "*   fit_intercept: whether to calculate the intercept for this model.\n",
        "*   positive: when 'true', forces the coefficients to be positive.\n",
        "\n",
        "Unfortunately, this model received a higher error than our previous model - 0.412.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LinReg hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "4AY8tifBzHU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU0H25DSETYt",
        "outputId": "325d2121-bc3e-466b-c02a-7e46cfad51f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'fit_intercept': False, 'positive': False}\n",
            "Mean squared error: 0.4126850356116859\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "linReg = LinearRegression()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {'fit_intercept': [True, False], 'positive': [True, False]}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(linReg, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_linReg = grid_search.best_estimator_\n",
        "best_linReg.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LinReg hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "RSldvDEUzRJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "linReg = LinearRegression()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {'fit_intercept': [True, False], 'positive': [True, False]}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(linReg, params, scoring='neg_mean_squared_error', cv=10, n_iter=4)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_linReg_randSearch = random_search.best_estimator_\n",
        "best_linReg_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ *  -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS97n9Ecx9Vf",
        "outputId": "35c96a8b-1c83-4572-b616-e9a08e2f675a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'positive': False, 'fit_intercept': False}\n",
            "Mean Squared Error: 0.41270973412510886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "putcpwQ1OAN6"
      },
      "source": [
        "# Now we decided to try some tree models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuHVFNoVLTof"
      },
      "source": [
        "# Decision Tree\n",
        "The first tree model we tried was the Decision Tree.\n",
        "\n",
        "We received a relatively low error of 0.296.\n",
        "\n",
        "We chose to tune the following hyperparameters:\n",
        "\n",
        "*   splitter: the strategy used to choose the split at each node.\n",
        "*   max_depth: the maximum depth of the tree.\n",
        "*   min_samples_split: the minimum number of samples required to split an internal node.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DecTree hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "sRpVCd94zhMF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsm2gi_IRD0X",
        "outputId": "f091d230-fb74-420f-ba98-6bf99118e4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 160, 'min_samples_split': 75, 'splitter': 'best'}\n",
            "Mean squared error: 0.30746276800817995\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'splitter' : ['best', 'random'],\n",
        "    'max_depth': [10,20,30,40,50,60,70,80,90,100,120,140,160,200,250,350,450],\n",
        "    'min_samples_split': [18,34,50,55,60,75,85,100,120,140,160,200,250,350,450]\n",
        "}\n",
        "\n",
        "# Creating the regressor\n",
        "dt = DecisionTreeRegressor()\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(dt, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_dt = grid_search.best_estimator_\n",
        "best_dt.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DecTree hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "CWA-__H3zl69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Creating the regressor\n",
        "dt = DecisionTreeRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'splitter' : ['best', 'random'],\n",
        "    'max_depth': randint(1, 500),\n",
        "    'min_samples_split': randint(2,200),\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(dt, params, scoring='neg_mean_squared_error', cv=15, n_iter=50)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_dt_randSearch = random_search.best_estimator_\n",
        "best_dt_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO58MR0xyJGK",
        "outputId": "88678422-7c0f-4668-f154-8a8911caef02"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 329, 'min_samples_split': 95, 'splitter': 'best'}\n",
            "Mean Squared Error: 0.2968629603389105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLZmAvsjS6sX"
      },
      "source": [
        "# Random Forest\n",
        "As the decision tree brought us best results so far, we expect the Random Forest to bring even better results, hoping it will improve the Decision Tree's faults.\n",
        "\n",
        "This model can also benefit our specific dataset because it works well on large datasets.\n",
        "\n",
        "The hyperparameter we tuned was:\n",
        "*   n_estimators- number of trees in the forest.\n",
        "*   max_depth- the maximum depth of the tree.\n",
        "*   min_sample_split-  the minimum number of samples required to split an internal node.\n",
        "\n",
        "We got an error of 0.203, the best model yet. Bam!\n",
        "\n",
        "We will now try to improve it using the boosting algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandForest hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "sdLDjUNsHBEV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOFlG26hCoSS",
        "outputId": "c44e622c-51a6-44d5-9de1-f5fbd99c94d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best param: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 500}\n",
            "Mean squared error: 0.20541880640392943\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': [100,200,500],\n",
        "    'max_depth': [None,5,10,20,60,100],\n",
        "    'min_samples_split': [2,5,10,15,30]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(rf, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best param:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_rf = grid_search.best_estimator_\n",
        "best_rf.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandForest hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "1Zj7cdFXHLat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Creating the regressor\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': randint(10, 600),\n",
        "    'max_depth': randint(1,150),\n",
        "    'min_samples_split': randint(2,30)\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(rf, params, scoring='neg_mean_squared_error', cv=10, n_iter=10)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_rf_randSearch = random_search.best_estimator_\n",
        "best_rf_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-w6JuZVHOZJ",
        "outputId": "d6b5c859-370e-401b-a22f-1d4ec61ed9f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 149, 'min_samples_split': 3, 'n_estimators': 409}\n",
            "Mean Squared Error: 0.2038784120586367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QwTJP53U4nN"
      },
      "source": [
        "# Adaptive Boosting\n",
        "The first boosting algorithm we chose was AdaBoost, a fast model with little tuning needed.\n",
        "\n",
        "The hyperparameters we tuned:\n",
        "\n",
        "*   n_estimators- the maximum number of estimators at which the boosting stops.\n",
        "*   learning_rate- the weight given to each regressor at each iteration.\n",
        "\n",
        "There is a tradeoff between these two parameters.\n",
        "\n",
        "In contrast to what we thought would happen, this Model did not improve our Random Forest model, as we got an error of 0.429. :(\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoost hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "YrzVkt3mHoqw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDPdIMjTP8Li",
        "outputId": "914384d5-d4b9-441e-fe61-f1b67d200bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.05, 'n_estimators': 100}\n",
            "Mean squared error: 0.4298362418105908\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "adaB = AdaBoostRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': [10, 25, 50, 100, 150, 250, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(adaB, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_adaB = grid_search.best_estimator_\n",
        "best_adaB.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoost hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "mJt-YfAhHsLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Creating the regressor\n",
        "adaB = AdaBoostRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': randint(2, 500),\n",
        "    'learning_rate': uniform(0.001, 1.0),\n",
        "    'loss':('linear', 'square'),\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(adaB, params, scoring='neg_mean_squared_error', cv=10, n_iter=20)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_adaB = random_search.best_estimator_\n",
        "best_adaB.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOhyMp2uH4Z2",
        "outputId": "7de010e5-cfa5-497c-f91f-162ea24886f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.21975160548736505, 'loss': 'linear', 'n_estimators': 43}\n",
            "Mean Squared Error: 0.43143590475161203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwjFTvtDX1wX"
      },
      "source": [
        "# Gradient Boosting\n",
        "The second boosting model we tried wad Gradient Boosting.\n",
        "\n",
        "This model usually has good performance, so we hoped that unlike the AdaBoost model, it will improve the Random Forest model's accuracy.\n",
        "\n",
        "The hyperparameters we tuned are:\n",
        "\n",
        "*   learning_rate- shrinks the contribution of each tree by learning_rate value.\n",
        "*   n_estimators- the number of boosting iterations to perform. Since this model is good at preventing overfitting, usually a larger number gives better performance.\n",
        "*   max_depth- maximum depth of the individual trees. It limits the number of nodes in the tree.\n",
        "\n",
        "There is a tradeoff between learning_rate and n_estimators.\n",
        "\n",
        "This model yielded the best accuracy so far- 0.178, even better than the Random Forest model! Double Bam!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GradBoost hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "Nf0ldJIDMY5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "gb = GradientBoostingRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'max_depth': [3, 4, 5],\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(gb, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_gb = grid_search.best_estimator_\n",
        "best_gb.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djFr5ImVSFj5",
        "outputId": "9423d430-d3f9-40fd-ea4e-0575fe6ed938"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
            "Mean squared error: 0.1807358517112084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GradBoost hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "GyCy3l4CMegk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Creating the regressor\n",
        "gb = GradientBoostingRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': randint(1, 600),\n",
        "    'learning_rate': uniform(0.001, 1.0),\n",
        "    'max_depth': randint(1, 10),\n",
        "    'subsample': uniform(0.01, 1.0),\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(gb, params, scoring='neg_mean_squared_error', cv=10, n_iter=20)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_gb_randSearch = random_search.best_estimator_\n",
        "best_gb_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x12viC3nMiI_",
        "outputId": "e4536c33-dcef-48e9-e5a6-458256434aea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.11467923734068841, 'max_depth': 5, 'n_estimators': 284, 'subsample': 0.6205903376755291}\n",
            "Mean Squared Error: 0.17868768891821396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I6Uy3ZMa03i"
      },
      "source": [
        "# XGBoost\n",
        "The last boosting model we tried was the XGBoost model.\n",
        "\n",
        "XGBoost has advantages regarding our dataset, as it works well with large datasets and is less prone to overfitting.\n",
        "\n",
        "Although it is harder to tune, we tried many different hyperparameters combinations, tuning the same hyperparameters as the previous model.\n",
        "\n",
        "We received an error of 0.183.\n",
        "It is not much worse than GB, but still does not improve it.\n",
        "\n",
        "1.5 Bam :/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "JGqTxRAsIm-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "xgb = XGBRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'max_depth': [4, 5, 6],\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(xgb, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_xgb = grid_search.best_estimator_\n",
        "best_xgb.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JotIqoeyThRi",
        "outputId": "24f06f00-bbc1-4255-ded7-f91bf273f8f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
            "Mean squared error: 0.18307160692312635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "v4_05AC_IrAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Creating the regressor\n",
        "xgb = XGBRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning and their respective search spaces\n",
        "params = {\n",
        "    \"n_estimators\": randint(100, 300),\n",
        "    \"learning_rate\": uniform(0.03, 0.3),\n",
        "    \"max_depth\": randint(2, 5),\n",
        "    \"subsample\": uniform(0.4, 0.6),\n",
        "    \"colsample_bytree\": uniform(0.3, 0.7),\n",
        "    \"gamma\": uniform(0, 0.5),\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(xgb, params, scoring='neg_mean_squared_error', cv=10, n_iter=30)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_xgb_randSearch = random_search.best_estimator_\n",
        "best_xgb_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYKT4jjwTuIJ",
        "outputId": "de8d4756-93d1-4644-d330-527cff42da28"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'colsample_bytree': 0.9621183606414874, 'gamma': 0.09315825812471878, 'learning_rate': 0.17471377826138554, 'max_depth': 4, 'n_estimators': 286, 'subsample': 0.4787287581947335}\n",
            "Mean squared error: 0.18599256314134693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Trees Regressor\n",
        "\n",
        "Another tree model we tried was the Extra Trees Regressor.\n",
        "\n",
        "This model improves the Random Tree model, as it is efficiant and faster than RF and handels over-fitting well.\n",
        "\n",
        "As expected, the error we received is better than the RF error -  0.194.\n",
        "\n",
        "The hyperparameters we tuned are the same as the previous ones with 2 additional hyperparameters:\n",
        "\n",
        "*   min_samples_leaf- the minimum number of samples required to be at a leaf node.\n",
        "*   max_features - the number of features to consider when looking for the best split.\n",
        "\n"
      ],
      "metadata": {
        "id": "FB3MECQ2Idfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "extra_trees_regressor = ExtraTreesRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(extra_trees_regressor, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_extra_trees_regressor = grid_search.best_estimator_\n",
        "best_extra_trees_regressor.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6lGa5EAIeJL",
        "outputId": "c4dbc5a2-08f2-430d-d886-5e535a88e460"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Mean squared error: 0.1948631420881139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZYN6UydR29"
      },
      "source": [
        "# Support Vector Regressor\n",
        "Now that we've finished trying our tree models, we will try the SVR model.\n",
        "\n",
        "The hyperparameters we tuned are:\n",
        "\n",
        "*   C - regularization parameter.\n",
        "*   Tol - stopping criterion.\n",
        "*   Kernel - kernel type to used in the algorithm.\n",
        "*   epsilon - specifies the epsilon-tube\n",
        "\n",
        "As we know, chosing a kernel function can be tricky. This is why we tried tuning it. We tried adding the 'poly' function in our search but found that this kernel function took to much time to train, so we dropped it.\n",
        "\n",
        "We received an error of 0.261."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVR hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "spBVPixzI6cH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYf240GB2euR",
        "outputId": "3ab2f461-1012-49fe-ece1-043b38af7995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'epsilon': 0.1, 'kernel': 'rbf', 'tol': 0.001}\n",
            "Mean squared error: 0.2613307174302152\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "svr = SVR()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'kernel': ['rbf', 'linear'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'tol': [0.01, 0.001, 0.0001],\n",
        "    'epsilon': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(svr, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_svr = grid_search.best_estimator_\n",
        "best_svr.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVR hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "Y5R18o63JAoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Creating the regressor\n",
        "svr = SVR()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'kernel': ['rbf', 'linear'],\n",
        "    'C': uniform(0.1, 10),\n",
        "    'tol': uniform(0.0001, 0.1),\n",
        "    'epsilon': uniform(0.01, 0.9)\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(svr, params, scoring='neg_mean_squared_error', cv=5, n_iter=10)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_svr_randSearch = random_search.best_estimator_\n",
        "best_svr_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XeAFRgRmHRo",
        "outputId": "d8396cbb-b441-4343-fcbb-e0a88a6e89aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 7.005136098736896, 'epsilon': 0.3190883775588658, 'kernel': 'rbf', 'tol': 0.07558260654009571}\n",
            "Mean Squared Error: 0.26212042704208044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso Regressor\n",
        "\n",
        "The next model we tried was Lasso Regressor - a linear model trained with L1 prior as regularizer.\n",
        "\n",
        "It should work well with preventing overfitting.\n",
        "\n",
        "The hyperparameters we tuned are:\n",
        "*   alpha - constant that multiplies the L1 term, and controls regularization strength.\n",
        "*   fit_intercept - whether to calculate the intercept for this model\n",
        "*   tol - tolerance for the optimization\n",
        "\n",
        "The error we received was 0.412."
      ],
      "metadata": {
        "id": "KUv1-SS9GYWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "lasso = Lasso()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10],\n",
        "    'fit_intercept': [True, False],\n",
        "    'tol': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_lasso = random_search.best_estimator_\n",
        "best_lasso.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qEpTbmsGfRb",
        "outputId": "1d2f1ebe-b717-4ee6-f198-decd42fbd87b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'tol': 0.001, 'fit_intercept': True, 'alpha': 0.001}\n",
            "Mean squared error: 0.4125626089540342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regressor\n",
        "\n",
        "The next model we tried was Ridge Regressor - linear least squares with l2 regularization.\n",
        "\n",
        "The prediction should be better than with L1 (the Lasso model).\n",
        "\n",
        "Also work well with preventing overfitting.\n",
        "\n",
        "The hyperparameters we tuned are the same as the Lasso hyperparameters with 1 additional hyperparameter:\n",
        "*   solver - the solver to use in the computational routines\n",
        "\n",
        "The error we received was 0.412 - same error as Lasso."
      ],
      "metadata": {
        "id": "Fx_X1NQirgPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RidgeReg hyperparameter tuning with Grid Search:"
      ],
      "metadata": {
        "id": "o0bwiuKKJFvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "ridge = Ridge()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha': [0.1, 1.0, 10, 35, 70, 100],\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr'],\n",
        "    'tol': [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_ridge = grid_search.best_estimator_\n",
        "best_ridge.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSb6fHvrrmVq",
        "outputId": "0e8ef749-0da6-408f-b0f8-e823189a56e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 35, 'fit_intercept': False, 'solver': 'lsqr', 'tol': 0.001}\n",
            "Mean Squared Error: 0.41256715952287226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RidgeReg hyperparameter tuning with Randomized Search:"
      ],
      "metadata": {
        "id": "fX-yYxktJJYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Creating the regressor\n",
        "ridge = Ridge()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha': uniform(0.1, 300),\n",
        "    'solver': ['auto', 'svd', 'cholesky', 'lsqr'],\n",
        "    'tol': uniform(0.00001, 0.1),\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using RandomizedSearch\n",
        "random_search = RandomizedSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=15, n_iter=100)\n",
        "random_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_ridge_randSearch = random_search.best_estimator_\n",
        "best_ridge_randSearch.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = random_search.best_score_ * -1\n",
        "print(\"Mean Squared Error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5pRgK2Yrq4C",
        "outputId": "8aab8138-3ea8-4337-8f93-480a9209c0b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 38.26325595371007, 'fit_intercept': False, 'solver': 'cholesky', 'tol': 0.016889321195045593}\n",
            "Mean Squared Error: 0.41265877438440834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernel Ridge\n",
        "\n",
        "In order to improve the previous model, we can try to transfer the data into another dimension.\n",
        "\n",
        "We then tried adding the kernel trick to the previous Ridge Regression, aka Kernel Ridge Reggression(a combination of both).\n",
        "\n",
        "The hyperparameters we tuned are:\n",
        "*   alpha - regularization strength.\n",
        "*   kernel - kernel mapping used internally.\n",
        "*   gamma - gamma parameter for the 'rbf' kernel, ignored by others.\n",
        "\n",
        "The error we received was 0.256.\n"
      ],
      "metadata": {
        "id": "7B5MuNr-HOSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "kernel_ridge = KernelRidge()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha': [0.01, 0.1, 1.0],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': [0.1, 1.0, 10]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(kernel_ridge, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_kernel_ridge = grid_search.best_estimator_\n",
        "best_kernel_ridge.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcnrFMhuHOrg",
        "outputId": "05d18c2f-e9cb-4ddf-b0d0-9655ef423581"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Mean squared error: 0.2560836149541546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The following algorithms received a high error, we will not elaborate on them because they are less relevant:"
      ],
      "metadata": {
        "id": "NWGuDmkBrHV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy Regressor"
      ],
      "metadata": {
        "id": "50B9-yycHnY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "dummy_regressor = DummyRegressor()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'strategy': ['mean', 'median', 'constant'],\n",
        "    'constant': [1, 2, 5, 10, 20, 30]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(dummy_regressor, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_dummy_regressor = grid_search.best_estimator_\n",
        "best_dummy_regressor.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8YFFMIXHnr1",
        "outputId": "479b7c50-ee3d-4018-f821-773d48b5d1ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'constant': 1, 'strategy': 'mean'}\n",
            "Mean squared error: 0.9986039648908245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Ridge"
      ],
      "metadata": {
        "id": "G81hmxP-H6LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "bayesian_regressor = BayesianRidge()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha_1': [0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001],\n",
        "    'alpha_2': [0.000001, 0.00001, 0.0001],\n",
        "    'lambda_1': [0.000001, 0.00001, 0.0001],\n",
        "    'lambda_2': [0.000001, 0.00001, 0.0001],\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(bayesian_regressor, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_bayesian_regressor = grid_search.best_estimator_\n",
        "best_bayesian_regressor.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEFnY2l3H6tI",
        "outputId": "4c7fa545-d20c-43ec-b369-f8a8e03c9c3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'alpha_1': 1e-09, 'alpha_2': 0.0001, 'fit_intercept': False, 'lambda_1': 0.0001, 'lambda_2': 1e-06}\n",
            "Mean squared error: 0.41267463440260893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elastic Net"
      ],
      "metadata": {
        "id": "-wPZIOovIw_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the regressor\n",
        "elastic_net_regressor = ElasticNet()\n",
        "\n",
        "# Defining the hyperparameters we're tuning\n",
        "params = {\n",
        "    'alpha': [0.01, 0.1, 1.0],\n",
        "    'l1_ratio': [0.25, 0.5, 0.75],\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Fitting the regressor using GridSearch\n",
        "grid_search = GridSearchCV(elastic_net_regressor, params, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "print(\"Best params:\", grid_search.best_params_)\n",
        "\n",
        "# Refitting the model with the best parameters on the real test set\n",
        "best_elastic_net_regressor = grid_search.best_estimator_\n",
        "best_elastic_net_regressor.fit(final_Xtrain, final_Ytrain)\n",
        "\n",
        "# Evaluating accuracy\n",
        "best_training_score = grid_search.best_score_ * -1\n",
        "print(\"Mean squared error:\", best_training_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JusvIKsdIxOg",
        "outputId": "ee808d32-0fe9-475e-cd24-958055a3e2cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.25}\n",
            "Mean squared error: 0.4134306586717454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W85eaJf1gNae"
      },
      "source": [
        "# Conclusion:\n",
        "After trying many models with different hyperparameters, we found that the best model for our dataset is Gradient Boosting with an error of 0.178 👑\n",
        "\n",
        "The models we experimented on were:\n",
        "\n",
        "\n",
        "*   K Nearest Neighbours\n",
        "*   Linear Regression\n",
        "*   Decision Tree\n",
        "*   Random Forest\n",
        "*   Adaptive Boosting\n",
        "*   Gradient Boosting\n",
        "*   XGBoost\n",
        "*   Extra Trees\n",
        "*   Support Vector Regression\n",
        "*   Lasso Regression\n",
        "*   Ridge Regression\n",
        "*   Kernel Ridge Regression\n",
        "*   Dummy Regression\n",
        "*   Bayesian Ridge Regression\n",
        "*   Elastic Net\n",
        "\n",
        "The preliminary data analysis helped us understand the model type to chose (regression). Also helped us decied on which regression models to try after determining what preproccesing actions are needed such as: filling missing values and scaling the data.\n",
        "\n",
        "The metrics we used in order to determine which model to chose was the sklearn.metrics.mean_squared_error metric.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data score on winning model:"
      ],
      "metadata": {
        "id": "fzNq0qlMOnJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "winning_model = best_gb_randSearch\n",
        "\n",
        "# Making predictions on the test data\n",
        "y_final_test_pred = winning_model.predict(finalX_test)\n",
        "\n",
        "# Evaluating accuracy\n",
        "winning_model_error = mean_squared_error(finalY_test, y_final_test_pred)\n",
        "\n",
        "print(\"Winning model mean squared error on test data:\", winning_model_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWeQ_x-_OxzN",
        "outputId": "94a13ddb-486e-432e-b8c1-99f2ff048e9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winning model mean squared error on test data: 1.4607825092632376\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rAxNDFdNcJ38",
        "spVmlI4cKbSt",
        "64P8RPQiLSTF",
        "QQa4wxriLf6q",
        "jD9c6eBmEZA5",
        "4AY8tifBzHU5",
        "RSldvDEUzRJR",
        "yuHVFNoVLTof",
        "sRpVCd94zhMF",
        "CWA-__H3zl69",
        "Y5R18o63JAoL",
        "Fx_X1NQirgPp",
        "o0bwiuKKJFvs",
        "fX-yYxktJJYe"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}